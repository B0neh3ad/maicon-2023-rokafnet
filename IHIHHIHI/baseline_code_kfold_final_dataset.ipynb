{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EWWya25RCpsZ"},"outputs":[],"source":["# 필요한 라이브러리를 설치합니다.\n","! pip install segmentation_models_pytorch\n","! pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23847,"status":"ok","timestamp":1700701938040,"user":{"displayName":"박진영","userId":"09127147183859643034"},"user_tz":-540},"id":"06dqd_qnCtQw","outputId":"5fbd74c4-3d77-4d4d-fa35-caeebbee86c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILMnPBxTB8fW"},"outputs":[],"source":["# 필요한 라이브러리들을 임포트합니다.\n","from glob import glob\n","import os\n","# Log in to your W&B account\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-j6sq5jfB8fa"},"source":["### 데이터 경로를 설정합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iIkeB47RB8fc"},"outputs":[],"source":["# 데이터 경로를 설정해줍니다.\n","data_directory = '/content/drive/MyDrive/Crack_Segmentation/dataset'\n","\n","# 학습용 데이터 경로와 마스크 경로를 설정해줍니다.\n","train_image_directory = os.path.join(data_directory, 'train', 'images') # 학습용 이미지 경로\n","train_mask_directory = os.path.join(data_directory, 'train', 'masks') # 학습용 마스크 경로\n","\n","# 테스트용 데이터 경로와 마스크 경로를 설정해줍니다.\n","test_image_directory = os.path.join(data_directory, 'test', 'images') # 테스트용 이미지 경로"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TvMJoqdWB8fd","outputId":"abd5bd9d-3e20-48f8-ded8-e3cb6af2718f"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습용 이미지 개수 : 478, 마스크 개수 : 378\n","평가용 이미지 개수 : 200\n"]}],"source":["# 각 경로에 존재하는 파일들의 경로를 리스트로 저장합니다.\n","train_image_paths = sorted(glob(os.path.join(train_image_directory, '*.jpg')))\n","train_mask_paths = sorted(glob(os.path.join(train_mask_directory, '*.png')))\n","\n","test_image_paths = sorted(glob(os.path.join(test_image_directory, '*.jpg')))\n","\n","# 각 이미지와 마스크의 수량을 체크하는 코드입니다.\n","print(f'학습용 이미지 개수 : {len(train_image_paths)}, 마스크 개수 : {len(train_mask_paths)}')\n","print(f'평가용 이미지 개수 : {len(test_image_paths)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJFk5eCtB8fd"},"outputs":[],"source":["# 이미지와 마스크의 경로 예시를 보고 혹시 파일 리스트가 순서대로 정렬되어 있지 않는지 확인해봅니다.\n","print(f'이미지 경로 예시 : {train_image_paths[:5]}')\n","print(f'마스크 경로 예시 : {train_mask_paths[:5]}')"]},{"cell_type":"markdown","metadata":{"id":"zJtiLIvpB8fe"},"source":["### Pytorch Dataset 클래스 정의\n","Pytorch Dataset 클래스는 AI 모델에 데이터를 입력하기 전에 데이터를 가공 및 표준화하는 역할을 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJlhu0oFB8fe"},"outputs":[],"source":["!pip install -U albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0qTbn-ktrER"},"outputs":[],"source":["# 필요한 라이브러리들을 임포트합니다.\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","import cv2\n","import numpy as np\n","import albumentations as A\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6viWROhB8ff"},"outputs":[],"source":["class SegDataset(Dataset):\n","    def __init__(self,df, data_path, transform = None,  mode='train'):\n","        '''\n","        image_paths: 이미지 경로들의 리스트\n","        mask_paths: 마스크 경로들의 리스트\n","        size: 이미지와 마스크를 리사이즈를 몇으로 할 지 결정하는 변수\n","        mode: train인지 test인지를 결정하는 변수\n","        '''\n","        self.df = df # data을 =\n","        self.data_path = data_path # 이미지 경로들의 리스트를 저장합니다.\n","        self.mask_paths = mask_paths # 마스크 경로들의 리스트를 저장합니다.\n","        self.mode = mode # 모드 변수를 저장합니다.\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths) # 데이터셋의 길이를 반환합니다.\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx] # idx 번째 이미지 경로를 불러옵니다. ex) 전체 이미지 중 첫 번째 이미지\n","        filename = os.path.basename(image_path) # 이미지 경로에서 이미지 파일의 이름을 불러옵니다. ex) train_0001.png\n","\n","        # image를 불러옵니다.\n","        image = Image.open(image_path) # 이미지 경로를 참조해 이미지를 불러옵니다. BGR 형태의 이미지입니다.\n","        image = image.convert('RGB') # RGB 형태로 변환합니다.\n","        image_size = torch.tensor(image.size) # 이미지의 사이즈를 저장합니다.\n","\n","        # image를 resize합니다.\n","        image = image.resize(self.resize)\n","\n","        # image를 torch tensor로 변환합니다.\n","        image = self.transform(image).float() # 딥러닝 모델의 입력은 float형이어야 합니다.\n","\n","        if self.mode == 'train' or self.mode == 'val':\n","            mask_path = self.mask_paths[idx] # idx 번째 마스크 경로를 불러옵니다.\n","\n","            # mask를 로드합니다.\n","            mask = Image.open(mask_path) # 마스크 경로를 참조해 마스크(정답)를 불러옵니다. Gray 이미지이며, 0부터 59 사이의 값을 가집니다.\n","\n","            # mask를 resize합니다.\n","            # 마스크 이미지는 resize 할때 iterpolation 방식에 각별히 주의해야 합니다.\n","            # linear interpolation 등을 사용하면 유효하지 않은 mask 값이 될 수 있습니다.\n","            # 따라서 주변에 있는 픽셀 값으로 interpolation 해야합니다.\n","            mask = mask.resize(self.resize, resample=Image.NEAREST) # 마스크를 리사이징합니다.\n","\n","            # mask를 torch tensor로 변환합니다.\n","            mask = torch.from_numpy(np.array(mask)).long() # 정답은 정수형이어야 하므로 long형으로 변환합니다.\n","\n","        else:\n","            mask = np.zeros(self.resize) # 테스트 데이터셋의 경우 마스크가 없으므로 0으로 채워진 마스크를 만듭니다.\n","        # 이미지, 마스크, 파일이름, 이미지 원본 사이즈 순으로 반환합니다.\n","        return image, mask, filename, image_size\n"]},{"cell_type":"markdown","metadata":{"id":"OKN3-Yx1B8ff"},"source":["###  모델 학습과 검증을 수행합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXPRdXp6Frez"},"outputs":[],"source":["import shutil\n","\n","# 학습된 모델을 저장할 경로를 설정합니다.\n","save_directory = '/content/drive/MyDrive/Crack_Segmentation/results/model'\n","\n","# 이미 경로가 있으면 삭제합니다.\n","if os.path.isdir(save_directory):\n","  shutil.rmtree(save_directory)\n","\n","# 경로를 생성합니다.\n","os.makedirs(save_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYixTJ0oB8fg"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","import torch.optim as optim\n","\n","split = 5\n","kfold = KFold(n_splits=split, shuffle=False)\n","\n","# 어떤 장치에서 학습할지 결정합니다. cuda는 gpu를 사용한다는 것을 의미합니다.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iw-jRaZgB8fg"},"outputs":[],"source":["# 필요한 라이브러리를 임포트합니다.\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","\n","num_epochs = 30  #학습할 에폭의 수를 결정합니다.\n","for i, (train_index, test_index) in enumerate(kfold.split(train_image_paths, train_mask_paths)):\n","    # WandB 사용을 위한 초기 설정을 합니다.\n","    wandb.init(\n","        project=\"crack_segmentation\",\n","        name=f\"fold_{i}\",\n","        config={\n","            \"encoder_name\" : 'timm-efficientnet-b0',\n","            'encoder_weights' : 'imagenet',\n","            \"learning_rate\": 0.02,\n","            \"epochs\": 10,\n","            \"batch_size\": 16,\n","            'learning_rate':0.01\n","        })\n","\n","    config = wandb.config\n","    # 데이터 split\n","\n","    fold_train_image_paths = np.array(train_image_paths)[train_index].tolist()[:100]\n","    fold_train_mask_paths = np.array(train_mask_paths)[train_index].tolist()[:100]\n","    fold_valid_image_paths = np.array(train_image_paths)[test_index].tolist()[:100]\n","    fold_valid_mask_paths = np.array(train_mask_paths)[test_index].tolist()[:100]\n","\n","    # 데이터셋 & 데이터 로더 생성\n","    train_dataset = SegDataset(fold_train_image_paths, fold_train_mask_paths, mode='train') # 학습 (train) 데이터 인스턴스 생성\n","    val_dataset = SegDataset(fold_valid_image_paths, fold_valid_mask_paths, mode='val') # 검증 (valid) 데이터 인스턴스 생성\n","    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2) # 학습 데이터 로더\n","    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2) # 검증 데이터 로더\n","\n","    # 모델 & optimizer & loss function 설정\n","    model = smp.Unet(classes=2,\n","                    encoder_name = config['encoder_name'],\n","                    encoder_weights = config['encoder_weights']).to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'])\n","\n","    loss_function = nn.CrossEntropyLoss()\n","\n","    best_acc = 0\n","\n","    for epoch in range(num_epochs):\n","\n","        # 학습을 수행합니다.\n","        model.train() # 모델을 학습 모드로 설정합니다.\n","\n","\n","        # 학습 데이터에 대한 정답율을 기록할 리스트를 선언합니다.\n","        train_accs = []\n","\n","        # 학습 데이터셋으로부터 데이터를 가져옵니다.\n","        for image, mask, filename, image_size in tqdm(train_loader, position=0, leave=True, desc=f'Fold : {i} epoch: {epoch} | train'):\n","\n","            # 가져온 데이터를 장치에 할당합니다.\n","            image = image.to(device) # 이미지의 차원은 [배치사이즈, 채널 수, 이미지 높이, 이미지 넓이]입니다.\n","            mask = mask.to(device) # 마스크의 차원은 [배치사이즈, 이미지 높이, 이미지 넓이]입니다.\n","\n","            # 모델의 출력값을 계산합니다.\n","            # 예측 결과인 pred_mask는 [배치사이즈, 클래스 수, 이미지 높이, 이미지 넓이]차원의 행렬 형태를 가집니다.\n","            pred_mask = model(image)\n","\n","            # loss를 계산합니다.\n","            loss = loss_function(pred_mask, mask)\n","\n","            # loss를 통해 모델을 학습합니다.\n","            optimizer.zero_grad() # gradient를 초기화합니다.\n","            loss.backward() # gradient를 계산합니다.\n","            optimizer.step() # gradient를 통해 파라미터를 업데이트합니다.\n","\n","            # argmax 연산을 통해 확률이 가장 높은 클래스를 예측값으로 선택합니다.\n","            # [배치사이즈, 클래스 수, 이미지 높이, 이미지 넓이] -> [배치사이즈, 이미지 높이, 이미지 넓이]로 변환됩니다.\n","            pred_mask = torch.argmax(pred_mask, dim=1)\n","\n","            # 해당 배치에 대한 성능 평가를 진행합니다.\n","            batch_acc =  (pred_mask == mask).float().mean().cpu().item()\n","            train_accs.append(batch_acc)\n","\n","        # 검증을 수행합니다.\n","        model.eval() # 모델을 검증 모드로 설정합니다.\n","\n","        # 검증 데이터에 대한 정답율을 기록할 리스트를 선언합니다.\n","        val_accs = []\n","\n","        # 검증 데이터셋으로부터 데이터를 가져옵니다.\n","        for image, mask, filename, image_size in tqdm(val_loader, position=0, leave=True, desc=f'Fold : {i} epoch: {epoch} | val'):\n","\n","                # 가져온 데이터를 장치에 할당합니다.\n","                image = image.to(device) # 이미지의 차원은 [배치사이즈, 채널 수, 이미지 높이, 이미지 넓이]입니다.\n","                mask = mask.to(device) # 마스크의 차원은 [배치사이즈, 이미지 높이, 이미지 넓이]입니다.\n","\n","                # 모델의 출력값을 계산합니다.\n","                # 예측 결과인 pred_mask는 [배치사이즈, 클래스 수, 이미지 높이, 이미지 넓이]차원의 행렬 형태를 가집니다.\n","                pred_mask = model(image)\n","\n","                # argmax 연산을 통해 확률이 가장 높은 클래스를 예측값으로 선택합니다.\n","                # [배치사이즈, 클래스 수, 이미지 높이, 이미지 넓이] -> [배치사이즈, 이미지 높이, 이미지 넓이]로 변환됩니다.\n","                pred_mask = torch.argmax(pred_mask, dim=1)\n","\n","                # 해당 배치에 대한 성능 평가를 진행합니다.\n","                batch_acc =  (pred_mask == mask).float().mean().cpu().item()\n","                val_accs.append(batch_acc)\n","\n","        train_acc = sum(train_accs) / len(train_accs)\n","        val_acc = sum(val_accs) / len(val_accs)\n","\n","        wandb.log({'train_acc': train_acc, 'val_acc': val_acc})\n","\n","        print(f'Fold : {i}, 에폭 : {epoch}, 학습 정확도 : {train_acc}, 검증 정확도 : {val_acc}')\n","\n","        # validation accuracy가 최고를 갱신하면 모델을 저장합니다.\n","        if val_acc > best_acc: # 이번 에폭의 기존의 최고 accuracy보다 높으면\n","            best_acc = val_acc # 최고 accuracy를 갱신하고\n","            torch.save(model.state_dict(), f'{save_directory}/best_model_fold_{i}.pt') # 모델을 저장합니다.\n","            print(f'Fold : {i}, Best performance at epoch {epoch} : {best_acc}')\n"]},{"cell_type":"markdown","metadata":{"id":"UJk56-MXB8fj"},"source":["# 추론을 수행합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5wY2CSkHLqr"},"outputs":[],"source":["# 예측 결과를 저장할 경로를 생성합니다.\n","pred_save_directory = '/content/drive/MyDrive/Crack_Segmentation/results/pred'\n","\n","# 이미 경로가 있으면 삭제합니다.\n","if os.path.isdir(pred_save_directory):\n","  shutil.rmtree(pred_save_directory)\n","\n","# 경로를 생성합니다.\n","os.makedirs(pred_save_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cD2qDRS3B8fj"},"outputs":[],"source":["# 학습이 완료된 모델을 로드합니다.\n","model = smp.Unet(classes=2, # 의류 종류 수에 맞게 클래스를 결정합니다.\n","                 encoder_name = 'timm-efficientnet-b0', # encoder 모델 구조를 결정합니다.\n","                 encoder_weights = 'imagenet') # encoder 모델에 어떤 사전학습 모델을 적용할지 지정합니다.\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0T56htqGHQR1"},"outputs":[],"source":["# 데이터셋 & 데이터로더\n","test_dataset = SegDataset(test_image_paths, mode='test') # 평가 (test) 데이터 인스턴스 생성\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2) # 평가 데이터 로더"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKqjgmvGB8fj"},"outputs":[],"source":["for image, _, filename, image_size in tqdm(test_loader, position=0, leave=True, desc=f'Prediction'):\n","    # 가져온 데이터를 장치에 할당합니다.\n","    image = image.to(device)\n","\n","    # 모델의 출력값을 계산합니다.\n","    for fold in range(split):\n","        model.load_state_dict(torch.load(f'{save_directory}/best_model_fold_{fold}.pt'))\n","        if fold == 0:\n","            pred_mask = model(image)\n","        else:\n","            pred_mask += model(image)\n","\n","    # argmax 연산을 통해 확률이 가장 높은 클래스를 예측값으로 선택합니다.\n","    pred_mask = torch.argmax(pred_mask, dim=1)\n","\n","    for i, a_pred_mask in enumerate(pred_mask):\n","        # pred_mask를 PIL image로 변환합니다.\n","        pred_mask_image = Image.fromarray(np.uint8(a_pred_mask.cpu().numpy()))\n","\n","        # 원본 이미지의 크기로 resize합니다.\n","        pred_mask_image = pred_mask_image.resize(image_size[i], resample=Image.NEAREST)\n","\n","        filename_ = filename[i].replace('.jpg', '.png')\n","\n","\n","        # 이미지를 저장합니다.\n","        pred_mask_image.save(f'{pred_save_directory}/{filename_}')"]},{"cell_type":"markdown","metadata":{"id":"1_knW7eEB8fk"},"source":["### 예측 결과물을 압축해서 제출합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HdsMx39NB8fk"},"outputs":[],"source":["import zipfile\n","\n","pred_files = glob(f'{pred_save_directory}/*.png')\n","\n","# 압축을 수행합니다.\n","with zipfile.ZipFile('results/out-of-fold.zip', 'w') as zip:\n","    for pred_file in pred_files:\n","        zip.write(pred_file, os.path.basename(pred_file))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utx7GNV3B8fk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnbR60TkB8fk"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}